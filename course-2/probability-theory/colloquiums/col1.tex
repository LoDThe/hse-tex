

\documentclass[a4paper]{article}
\usepackage{header}

% Use \begin{theorem*} instead of \begin{theorem}.
% Use \iff instead of \Leftrightarrow.

% Команды для ToC'a
\newcommand\enumtocitem[3]{\item\textbf{#1}\addtocounter{#2}{1}\addcontentsline{toc}{#2}{\protect{\numberline{#3}} #1}}
\newcommand\defitem[1]{\enumtocitem{#1}{subsection}{\thesubsection}}
\newcommand\proofitem[1]{\enumtocitem{#1}{subsubsection}{\thesubsubsection}}

\renewcommand{\o}{\operatorname{o}}

\newlist{colloq}{enumerate}{1}
\setlist[colloq]{label=\textbf{\arabic*.}}

\title{\Huge ТВиМС - Коллоквиум 1}
\author{
    Цирк Максимус | \href{https://t.me/ultrakekul}{telegram}
}
\date{Версия от {\ddmmyyyydate\today} \currenttime}

\begin{document}
    \maketitle
    
    \tableofcontents

    \newpage

    \section{Вопросы}

    \begin{colloq}

    \defitem{Дискретное вероятностное пространство. Свойства вероятностной меры на конечных и счётных множествах. Вероятностный алгоритм проверки числа на простоту.}
    
    	\begin{definition*}
    		Пусть задано некоторое множество возможных исходов (эксперимента) $\Omega = \{1, 2, \dots, n\}$. Это множество называют множеством элементарных исходов. Всякое подмножество $A \subset \Omega$ называют событием. Функцию $P: 2^{\Omega} \rightarrow [0, 1]$, удовлетворяющую следующим свойствам:
    		
    		(1) $P(\Omega) = 1$,
    		
    		(2) $A \cap B = P(A \cup B) = P(A) + P(B)$ (правило суммы или аддитивность), называют вероятностной мерой, а значение $P(A)$ - вероятностью события $A$.
   		\end{definition*}
   	
   		\textbf{Тест Ферма проверки числа на простоту.}
   			
   		Пусть дано некоторое натуральное число $N > 1$. Мы хотим проверить является ли это число простым. Можно перебирать все простые делители до $\sqrt{N}$, но это очень долго. Хотелось бы иметь более быстрый способ проверки. 
   		
   		Если $N$ простое число, то по малой теореме Ферма для всякого натурального числа $b$	такого, что НОД$(b, N) = 1$, число $b^{N-1} - 1$ делится на $N$. Следовательно, если для некоторого $b$, удовлетворяющего условию НОД$(b, N) = 1$, число $b^{N-1} - 1$ не делится на $N$,	то $N$ не является простым. В этом случае будем говорить, что $N$ не проходит тест Ферма по основанию $b$. Это наблюдение используют для построения простейшего алгоритма проверки числа на простоту: выберем случайное число $b$ из промежутка $2, \dots , N - 1$; если НОД$(b, N) \neq 1$, то $N$ составное; если НОД$(b, N) = 1$, но $b^{N-1} - 1$ не делится на $N$, то $N$ составное. В ином случае $N$ - скорее простое. 
   		
   		Предположим, что существует хотя бы одно число $a$: НОД$(a, N) = 1$ и $a^{N-1}-1$ не делится на $N$. Посмотрим, с какой вероятностью алгоритм выдаст ответ, что $N$ - скорее простое. Пусть $Z_N^*$ - группа всех чисел из промежутка ${1, \dots , N-1}$, взаимно простых с $N$. Если $N$ проходит тест для основания $b \in Z_N^*$ , то для основания $ab$ число $N$ уже тест не проходит. В противном случае $(ab)^{N-1} \equiv 1(mod$ $N)$ и $(b^{-1})^{N-1} \equiv 1(mod$ $N)$. Следовательно, $a^{N-1} \equiv (b^{-1})^{N-1} (ab)^{N-1} \equiv 1$, что противоречит предположению. Таким образом, каждому	основанию $b$, для которого $N$ проходит тест, можно сопоставить основание $ab$, для которого $N$ тест не проходит. Значит, оснований, для которых $N$ не проходит тест, не меньше, чем оснований, для которых $N$ проходит тест на простоту. Поэтому в данной ситуации вероятность получить ответ, что $N$ скорее простое, не более $\dfrac{1}{2}$. Если независимым образом повторять описанную процедуру $k$ раз, то вероятность получить неверный ответ не более ${\left( \dfrac{1}{2} \right)}^k$. Отметим, что бывают числа, которые проходят тест для всех оснований $b$. Это числа Кармайкла, например $561$. Для них описанный алгоритм по понятным причинам не применим.
   		
   	\defitem{Формула включений-исключений. Парадокс распределения подарков. Задача про конференцию.}
   	
	   	\begin{proposal} Формула включений и исключений.
	   		Для произвольных событий $A_1, A_2, A_3, \dots, A_n$ верно равенство $P(A_1 \cup A_2 \cup \dots \cup A_n) = \sum_{k = 1}^{n} (-1)^{k - 1} \sum_{i_1 < \dots < i_k} P(A_{i_1} \cap A_{i_2} \cap \dots \cap A_{i_k})$.	   		
	   	\end{proposal}
   	
   		\begin{proof}
   			Докажем утверждение по индукции. База: $P(A_1 \cup A_2) = P((A_1 \ A_2) \cup (A_2 \ A_1) \cup (A_1 \cap A_2)) = P(A_1 \ A_2) + P(A_2 \ A_1) + P(A_1 \cap A_2) = P(A_1) + P(A_2) - P(A_1 \cap A_2)$.
   			
   			Предположим, что утверждение выполняется для $n$ множеств. Проверим, что оно выполнено и для $n+1$. 
   			
   			$P(A_1 \cup \dots \cup A_{n+1}) = P(A_1 \cup \dots \cup A_n) + P(A_{n+1}) - P((A_1 \cap A_{n+1}) \cup \dots \cup (A_n \cap A_{n+1})) = \\ \sum_{k = 1}^{n} (-1)^{k - 1} \sum_{i_1 < \dots < i_k} P(A_{i_1} \cap A_{i_2} \cap \dots \cap A_{i_k}) + P(A_{n+1}) - \sum_{k = 1}^{n} (-1)^{k - 1} \sum_{i_1 < \dots < i_k} P(A_{i_1} \cap A_{i_2} \cap \dots \cap A_{i_k} \cap A_{n+1}) = \sum_{k = 1}^{n + 1} (-1)^{k - 1} \sum_{i_1 < \dots < i_k} P(A_{i_1} \cap A_{i_2} \cap \dots \cap A_{i_k})$.
   		\end{proof}
   	
   		\textbf{Парадокс распределения подарков}
   		
   		Пусть $n$ человек принесли подарки друг для друга. Затем эти подарки сложили в мешок и каждый наугад вынул из мешка себе подарок. Какова вероятность того, что конкретный человек вынул подарок, который он принёс? Какова вероятность того, что никто не вытащил подарок, который сам принёс?
   		
   		Пространство исходов состоит из всех возможных перестановок чисел $1, 2, \dots , n$, причём все перестановки являются равновозможными. Значит вероятность конкретной перестановки равна $\dfrac{1}{n!}$. Событие, состоящее в том, что конкретный человек вытащил подарок, который сам принёс, состоит из $(n - 1)!$ исходов. Следовательно, вероятность такого
   		события равна $\dfrac{1}{n}$. При больших $n$ эта вероятность стремится к нулю.	Можно было бы думать, что вероятность события: ни один человек не вытащил подарок, который сам принёс, стремится к единице, но это ошибочное мнение.
   		
   		Пусть $A_k$ - событие состоящее в том, что $k$-й человек вытащил свой подарок. Тогда $A_1 \cup \dots \cup A_n$ - это событие, состоящее в том, что хотя бы один вытащил свой подарок. По	формуле включения и исключения: 
   		
   		$P(A_1 \cup A_2 \cup \dots \cup A_n) = \sum_{k = 1}^{n} (-1)^{k - 1} C_n^k \dfrac{(n - k)!}{n!} = \sum_{k = 1}^{n} \dfrac{(-1)^{k-1}}{k!}$.
   		
   		Таким образом, вероятность того, что ни один человек не вытащил подарок, который сам принёс, равна $1 - P(A_1 \cup \dots \cup A_n) = 1 - 1 + \dfrac{1}{2!} - \dfrac{1}{3!} + \dots$ и стремится к $\dfrac{1}{e}$.
   		
   		\textbf{Задача про конференцию.}
   		В научном центре работают специалисты по 60 различным разделам компьютерных наук. Известно, что по каждому разделу в центре работает ровно 7 учёных, причём вполне может быть, что один учёный является специалистом сразу по нескольким направлениям. Все учёные должны принять участие в одной (и только одной) из двух конференций, одна из которых проходит в Канаде, а другая в Австралии. Оказывается, что всегда можно так распределить учёных по этим конференциям, что на каждой конференции будут присутствовать специалисты по всем 60 направлениям компьютерных наук.
   		
   		Будем для каждого учёного выбирать конференцию простым подбрасыванием правильной монеты. Для $k$-го направления рассмотрим событие $A_k$, состоящее в том, что среди учёных этого направления окажутся и те, которые поехали в Канаду, и те, которые поехали в Австралию. Вероятность этого события равна $1-2^{-6}$ (нас устроят все исходы кроме двух, когда все отправились на конференцию в одну страну). Остаётся заметить, что количество событий $A_k$ равно 60 и вероятность каждого события больше $1 - \dfrac{1}{60}$.
   	
   	\defitem{Условная вероятность. Формула полной вероятности. Формула Байеса. Независимые события. Отличие попарной независимости от независимости в совокупности. Задача о	билетах к экзамену.}
   	
   	\begin{definition*}
   		Пусть $P(B) > 0$. Условной вероятностью события $A$ при условии $B$ называется число $P(A|B) = \dfrac{P(A \cap B)}{P(B)}$.
   		Если фиксировать событие $B$, то функция $P(\cdot|B)$ является новой вероятностной мерой, т.е. удовлетворяет свойствам (1) и (2) (или (2)', если таковой была исходная вероятностная мера $P$). Равенство из определения часто переписывают в виде $P(A \cap B) = P(A|B)P(B)$ и называют правилом произведения.
   		% В конспекте явно указано (ii)', но свойство (ii) со штрихом само по себе нигде в конспектаз ранее не указано. Следует прочекать лекцию 1, где эти свойства оглашались, вдруг я упустил формулировку. В случае её наличия, следует добавить её в первый пункт.
   	\end{definition*}
   
   	\begin{theorem*} (Формула полной вероятности)
   		
   		Пусть $\Omega = A_1 \cup A_2 \cup \dots \cup A_n$ и $A_i \cap A_j = \emptyset$ для всех $i \neq j$. Предположим, что $P(A_i) > 0$. Тогда для каждого события $B$ имеет место равенство $P(B) = \sum_i P(B|A_i)P(A_i)$.
   	\end{theorem*}
   
   	\begin{proof}
   		Имеем равенства $P(B) = \sum_i P(B \cap A_i) = \sum_i P(B|A_i)P(A_i)$.
   		
   		
   		На практике часто возникает ситуация, когда заданы или легко вычисляются именно	условные вероятности. Предположим, что задано разбиение на попарно непересекающиеся, непустые события $A_i$, их вероятности $p_i$ и условные вероятности $P_i(\cdot) = P(\cdot|A_i)$ (произвольная вероятностная мера со свойством $P_i(B) = P_i(B \cap A_i))$. Тогда формула полной вероятности позволяет определить вероятностную меру $P$, для которой числа $p_i$ и $P_i(B)$ действительно являются вероятностями $A_i$ и условными вероятностями $B$ при условии $A_i$. Более того, формула полной вероятности гарантирует, что такая вероятностная	мера только одна.
   		Действительно, положим $P(B) = \sum_i P_i(B)p_i$.
   		
   		В данном случае свойства (1) и (2) очевидно выполняются, кроме того $P(A_i) = p_i$ и $P(B \cap A_i) = P_i(B)p_i$.
   	\end{proof}
   
	\begin{theorem*} (Формула Байеса)
		
		Пусть $P(A) > 0$ и $P(B) > 0$. Тогда имеет место равенство $P(A|B) = \dfrac{P(B|A)P(A)}{P(B)}$.
	\end{theorem*}

	\begin{proof}
		Достаточно заметить, что $P(A|B)P(B) = P(A \cap B) = P(B|A)P(A)$.
	\end{proof}

	\begin{definition*}
		События $A$ и $B$ называются независимыми, если $P(A \cap B) = P(A)P(B)$. В противном случае говорят, что события являются зависимыми.
	\end{definition*}

	Заметим, что независимость в совокупности (т.е. в случае, когда для $A_1, A_2, \dots, A_n$ верно $P(A_{i_1} \cap A_{i_2} \cap \dots \cap A_{i_k}) = P(A_{i_1})P(A_{i_2}) \dots P(A_{i_k})$ для произвольного $k \in \{2, \dots, n\}$ и произвольных $1 \leqslant i_1 \leqslant i_2 \leqslant \dots \leqslant i_k \leqslant n$) не совпадает с попарной независимостью. Это иллюстрируется парадоксом независимости:
	
	Бросаем правильную монету два раза. Рассмотрим 3 события $A$ - при первом броске выпал орёл, $B$ - про втором броске также выпал орёл, $C$ - орёл выпал только один раз. Все эти события попарно независимы, но в совокупности они не являются независимыми, поскольку любые два из них однозначно определяют третье, например пересечение $A$ и $B$ исключает $C$, таким образом $P(A \cap B \cap C) = 0 \neq P(A)P(B)P(C)$.
	
	\textbf{Задача о билетах к экзамену}
	
	Программа экзамена содержит $N$ билетов, а студент выучил только $n$. На экзамене
	студенты по очереди подходят и тянут билет. Зависит ли вероятность вытянуть "хороший"
	билет от места в очереди?
	
	Пусть студент стоит $k+1$-м в очереди и пусть событие $A$ заключается в том, что студент
	вытянул "хороший" билет. Пусть событие $A_j$ заключается в том, что первые $k$ студентов
	вытянули $j$ "хороших" билетов. 
	
	Тогда $P(A_j) = \dfrac{C_n^j C^{k-j}_{N-n}}{C_N^k}$. Таким образом,	$P(A) = \sum_{j=0}^{min\{k, m\}} P(A|A_j)P(A_j) = \sum_{j=0}^{min\{k, m\}} \dfrac{n-j}{N-k} \dfrac{C_n^j C^{k-j}_{N-n}}{C_N^k} = \\ = \dfrac{n}{N} \sum_{j=0}^{min\{k, m\}} \dfrac{C_{n-1}^j C^{k-j}_{(N - 1) - (n - 1)}}{C_{N - 1}^k} = \dfrac{n}{N}$.
   	
   	\defitem{Задача о сумасшедшей старушке. Парадокс Байеса. Парадокс Монти Холла.}
	
	\textbf{Задача о сумасшедшей старушке}
	
	У нас $N \geq 2$ людей стоят ждут посадки в самолет. Одним из этих людей оказывается сумасшедшая старушка, которая всех расталкивает и садится первой на случайное место. Дальше заходят по очереди остальные пассажиры. Тк все люди очень вежливые(кроме данной старушки), если их место уже было занято, то они садятся на другое рандомное место.
	
	Мы хотим посчитать вероятность, с которой $N$-ый(последний) человек сядет на свое место. Рассмотрим по индукции. 
	
	База:  $N=2$
	
	$P_N = \cfrac 12$ - шанс, что $N$ человек сел на свое место (старушка села на место последнего пассажира или она села на свое)
	
	Шаг: Для всех $k \leq N$ людей верен факт $P_{k} = \cfrac 12$, рассмотрим для $P_{N+1}$
	
	Зададим 2 события: 
	
	$A_i$ - старушка села на место $i$ человека
	
	$B$ - последний пассажир ($N+1$) сел на свое место (вводим чисто, чтобы удобнее было работать)
	
	Тогда хотим найти: $P_{N+1}=  P(B) = \sum_i P(A_i) \cdot P(B | A_i)$ - формула полной вероятности	
	
	$P(A_i) = \cfrac 1{N+1}$ - старушка садится на произвольное место из $N+1$
	
	$P(B | A_1) = 1$ - если старушка села на свое место(считаю, что она 1 пассажир)
	
	$P(B | A_{N+1}) = 0$ - $N+1$ не сядет на свое место, если там уже сидит старушка
	
	$P(B | A_i) = \cfrac 12$ - в остальных случаях 
	
	Тогда: $P(B) = \sum_i P(A_i) \cdot P(B | A_i) = \cfrac 1{N+1} \cdot 1 + \cfrac 1{N+1} \cdot 0 + \cfrac 1{N+1} \cdot \cfrac 12 \cdot (N+1 - 2) = \cfrac {2 + N-1}{2(N+1)} = \cfrac 12$
	
	$\Rightarrow P_N = \cfrac 12$ - вероятность, что последний человек сядет на свое место 
	
	\textbf{Парадокс Байеса}
	
	Предположим у нас есть очень редкая болезнь (читай ковид) 
	
	$P(Z_+) = 0.001$ - шанс, что ты больной
	
	$P(Z_-) = 0.999$ - шанс,  что здоров
	
	Теперь также положим, что у нас есть тест на эту болезнь:
	
	$P(T_+ | Z_+) = 0.99$ - ты болен, тест показал,  что ты болен
	
	$P(T_+ | Z_-) = 0.01$ - ты здоров, но тест ошибся и показал, что ты болен
	
	Теперь, скажем, пришел положительный тест. Посчитаем шанс, с которым ты здоров. (те тест ошибся)
	
	$P(Z_- | T_+) = \cfrac{P(T_+ | Z_-) \cdot P(Z_-)}{P(T_+)}$ - по формуле Байеса
	
	Надо посчитать $P(T_+)$ :
	
	$P(T_+) = P(Z_-) \cdot P(T_+ | Z_-) + P(Z_+) \cdot P(T_+ | Z_+) = 0.999 \cdot 0.01 + 0.001 \cdot 0.99 = 0.01098$ - по формуле полной вероятности
	
	Тогда: $P(Z_- | T_+) = \cfrac{P(T_+ | Z_-) \cdot P(Z_-)}{P(T_+)}  = \cfrac{0.01 \cdot 0.999}{0.01098} \approx 0.9098 \geq 0.9$ 
	
	те если тебе пришел положительный тест, ты здоров с шансом больше $90\%$(интуитивно это очень сложно понять, но это объясняется редкостью нашего теоретического заболевания). Поэтому и надо делать больше 1 теста.
	
	\textbf{Парадокс Монти Холла}
	
	Есть игра: 3 двери за 1 из них автомобиль, за 2-мя другими - козы. Ты выбираешь дверь, после чего ведущий открывает 1 из оставшихся, за которой находится коза(он знает где автомобиль) и предлагает тебе изменить выбор. Банальный вопрос: стоит ли это делать? (увеличатся ли шансы найти автомобиль)
	
	Пускай выбрали 1 дверь, а ведущий открыл 3(чисто для нумерации). Введем события:
	
	$A_i $ - автомобиль за $i$-ой дверью 
	
	$B $ - ведущий открыл 3-ю дверь 
	
	Тогда можем определить следующие вероятности:
	
	$P(B| A_1) = \cfrac 12$ - автомобиль за 1 дверью, ведущий случайно выбирает дверь
	
	$P(B| A_2) = 1$ - если автомобиль в 3, а выбрали 1, то ведущий точно откроет 2.
	
	$P(B| A_3) = 0$ - ведущий не будет открывать автомобиль -\_-
	
	Посмотрим на шансы дверей после открытия 3-ей:
	
	$P(A_2| B) = \cfrac {P(B| A_2) \cdot A_2}{P(B)} = \cfrac {P(B| A_2) \cdot A_2}{P(A_1)\cdot P(B| A_1) + P(A_2)P(B| A_2) + P(A_3)P(B| A_3)} = \cfrac {1 \cdot 1/3}{1/3 \cdot 1/2 + 1/3 \cdot 1 + 1/3 \cdot 0} = \cfrac {1}{1/2 + 1} = \cfrac 23$
	
	P.S. Парадоксом называется тк интуитивно многие считают, что вероятности стали $\cfrac 12$ и выбор не важен
   	
   	\defitem{Случайные величины на дискретном вероятностном пространстве, их распределение. Примеры дискретных распределений. Совместное распределение случайных величин.	Независимые случайные величины. Эквивалентное определение независимости случайных величин.}
   	
   	\begin{definition*}
   		Случайной величиной на дискретном вероятностном пространстве $\Omega = {\omega_1, \omega_2, \dots}$ называют произвольную функцию $X: \Omega \rightarrow R$.
   	\end{definition*}
   
   	\begin{definition*}
   		Пусть $X$ - случайная величина на дискретном вероятностном пространстве и $x_1, \dots, x_n, \dots$ - все различные значения $X$. Распределением случайной величины $X$ называется новая вероятностная мера $\mu_X$ на пространстве $\{x1, \dots, xn, \dots \}$, для которой $\mu_X ({xj}) = P(\omega: X(\omega) = x_j)$.
   	\end{definition*}
   
   	\begin{example}
   		
   	\textbf{Бернуллиевская случайная величина.}
   		
   	\begin{tabular}{ | c | c | }
   		\hline
   		 0 & 1  \\ \hline
   		 q & p \\
   		\hline
   	\end{tabular}
   
   	Эта случайная величина моделирует однократное бросание монеты с вероятностью орла $p$. Такая случайная величина обычно появляется, как индикатор какого-то события $A$.
   	\end{example}
   
   \begin{example}
   	
   	\textbf{Схема Бернулли (биномиальное распределение).}
   	
   	\begin{tabular}{ | c | c | c | c | c | c |}
   		\hline
   		0 & 1 & $\dots$ & $k$ & $\dots$ & $N$ \\ \hline
   		$q^N$ & $Npq^{N-1}$ & $\dots$ & $C_N^k p^k q^{N-k}$ & $\dots$ & $p^N$ \\
   		\hline
   	\end{tabular}
   	
   	$\Omega$ - все возможные наборы последовательностей длины $N$ из 0 и 1. Вероятностная мера $P$ задана на каждом элементарном исходе следующим правилом: если исход содержит $k$ единиц, то вероятность этого исхода $p^k	q^{N-k}$, где $p, q \geqslant 0$ и $p + q = 1$.
   	
   	Случайная величина $X(\omega)$ - число единиц в исходе $\omega$. Её таблица представлена выше.
   \end{example}

	\begin{example}
		
		\textbf{Геометрическое распределение.}
		
		\begin{tabular}{ | c | c | c | c | c |}
			\hline
			0 & 1 & $\dots$ & $k$ & $\dots$ \\ \hline
			$p$ & $pq$ & $\dots$ & $p q^{k-1}$ & $\dots$ \\
			\hline
		\end{tabular}
		
		Данная случайная величина моделирует подбрасывание монетки до первого успеха.
	\end{example}

	\begin{example}
		
		\textbf{Распределение Пуассона.}
		
		\begin{tabular}{ | c | c | c | c | c |}
			\hline
			0 & 1 & $\dots$ & $k$ & $\dots$ \\ \hline
			$e^{-\lambda}$ & $\dfrac{\lambda}{1!} e^{-\lambda}$ & $\dots$ & $\dfrac{\lambda^k}{k!} e^{-\lambda}$ & $\dots$ \\
			\hline
		\end{tabular}
	
	\end{example}

	\begin{definition*}
	Пусть $X, Y$ - две случайные величины на дискретном вероятностном пространстве с множествами (различных) значений $\{x_1, x_2, \dots, x_k, \dots\}$ и $\{y_1, y_2, \dots, y_k, \dots\}$ соответственно. Их совместным распределением называется вероятностная мера $\mu_{(X,Y)}$ на вероятностном пространстве всех пар $(x_j, y_k)$, для которой 
	
	$\mu_{(X,Y)}(\{(x_j, y_k)\}) = P(\omega: X(\omega) = x_j, Y(\omega) = y_k) = P(\{\omega: X(\omega) = x_j\} \cap \{\omega: Y(\omega) = y_k)\}$
	
	Аналогично определяется совместное распределение трёх и более случайных величин.
   	\end{definition*}
   
   	\begin{definition*}
   		Случайные величины $X, Y$ с множествами значений $\{x_1, \dots , x_k, \dots \}$ и $\{y_1, \dots , y_k, \dots \}$ соответственно называются независимыми, если $\forall k,j: \mu_{(X,Y)}(\{(x_j, y_k)\}) = \mu_{X}(\{x_j\}) \cdot \mu_{Y}(\{y_k\})$. Или, другими словами: $\forall k,j: P(\omega: X(\omega) = x_j, Y(\omega) = y_k) = P(\{\omega: X(\omega) = x_j\} \cdot \{\omega: Y(\omega) = y_k)\}$.
   		
   		Аналогично определяется независимость трёх и более случайных величин.   		
   	\end{definition*}
   	\defitem{Математическое ожидание случайной величины на дискретном вероятностном пространстве, эквивалентный способ вычисления математического ожидания. Математическое ожидание функции от случайной величины. Свойства математического ожидания: линейность, ожидание неотрицательной случайной величины, неотрицательная случайная величина с нулевым математическим ожиданием, связь модуля ожидания и ожидания модуля случайной величины, математическое ожидание произведения независимых случайных величин. Балансировка векторов.}
   	
   	\defitem{Дисперсия, ковариация и коэффициент корреляции. Их связь и основные свойства: билинейность ковариации, случайная величина с нулевой дисперсией, дисперсия линейного образа случайной величины, дисперсия суммы независимых случайных величин. Неравенство Коши-Буняковского и геометрическая интерпретация ковариации, дисперсии и коэффициент корреляции. Вычисление ожидания и дисперсии у биномиального распределения.}
   	
   	\defitem{Неравенство Чебышёва. Закон больших чисел в слабой форме.}
   	
	\textbf{Неравенство Чебышёва.}
	
	Если $X \geqslant 0$ п.н., то для всякого $t > 0$ верно неравенство $P(\omega: X(\omega) \geqslant t) \leqslant \dfrac{\mathbb{E}X}{t}$.
	
	\begin{proof}
		Пусть $A = {\omega:X(\omega) \geqslant t}$. Тогда $X \geqslant t \cdot I_A$, и значит $\mathbb{E}X \geqslant tP(A)$.
	\end{proof}

	\begin{proposal}
		Пусть $\mathbb{E}X^2 < \infty$. Тогда для каждого $\varepsilon > 0$ выполнено $P(|X - \mathbb{E}X| \geqslant \varepsilon) \leqslant \dfrac{\mathbb{D}X}{\varepsilon^2}$.
	\end{proposal}

	\begin{proof}
		Применяем неравенство Чебышёва к случайной величине $|X - \mathbb{E}X|^2$.
	\end{proof}
		   	
   	\defitem{Теорема Муавра-Лапласа (формулировка локальной и интегральной теорем, доказательство локальной теоремы в симметричном случае, идея доказательства интегральной теоремы).}

    \end{colloq}

\end{document}
