\section{Теорема о сходимости градиентного спуска для линейной системы с симметричной положительно определенной матрицей.}

\begin{theorem*}[Сходимость наискорейшего спуска]
    Пусть $A = A^T > 0$ и $x_k$ сгенерировано с помощью метода наискорейшего спуска, тогда для ошибки $e_k := x_* - x_k$ справедливо:
    $$||e_{k + 1}||_A \leq \frac{cond_2(A) - 1}{cond_2(A) + 1} ||e_k||_A$$
\end{theorem*}

\begin{proof}
    Заметим, что оценку лучше действительно нельзя получить, но данным доказательством мы не отвечаем на вопрос ''почему это так?''.
    
    Сначала вспомним, что при обсуждении градиентного спуска, идея состояла в том, чтобы переформулировать систему линейных уравнений в виде минимизации некоторого функционала. В качестве такого функционала мы выбрали $f(x) = \frac{1}{2}x^TAx - x^Tb$. При этом $||x - x_*||^2_A = x^TAx - 2x^Tb + const$, то есть решение системы $x_*$ будет единственной точкой глобального минимума как для $f(x)$, так и для $||x - x_*||^2_A$.
    
    \begin{enumerate}
        \item Нам без разницы, что мы будем минимизировать: $f(x)$ или честную $A$-норму ошибки, $||x - x_*||^2_A$. Результат не должен поменяться, поэтому для теоретических выкладок мы будем минимизировать именно честную $A$-норму ошибки.
        $$2f(x) + const = ||x - x_*||^2_A \Rightarrow$$
        $$\Rightarrow \tau_k = \underset{\tau}{\operatorname{argmin}} f(x_k + \tau r_k) = \underset{\tau}{\operatorname{argmin}} ||x_k + \tau r_k - x_*||^2_A$$
        
        \item Теперь запишем $A$-норму ошибки, сдвиг вдоль градиента на параметр $\tau$ хотим выбрать оптимальным образом из условия минимизации $||x_k + \tau r_k - x_*||^2_A$.
        $$||e_{k + 1}||^2_A \overset{1.}{\operatorname{\textrm{ } = \textrm{ }}} \underset{\tau}{\operatorname{min}} ||x_k + \tau r_k - x_*||^2_A \overset{\forall t}{\operatorname{\textrm{ } \leq \textrm{ }}} ||x_k + tr_k - x_*||^2_A = \Big[ \textrm{т.к. } x_k - x_* = e_k \textrm{ и } r_k = -Ae_k \Big] = ||(I - tA)e_k||^2_A =$$
        $$= \Big[ \textrm{теперь вспомним про $A = A^T$ и заметим, что } ||y||^2_A = y^TAy = y^TA^{1/2}A^{1/2}y = (A^{1/2}y)^TA^{1/2}y = ||A^{1/2}y||^2_2 \Big] =$$
        $$= ||A^{1/2}(I - tA)e_k||^2_2 = ||(I - tA)A^{1/2}e_k||^2_2 \leq ||I - tA||^2_2  \cdot ||e_k||^2_A$$
        
        \item В предыдущем пункте мы свели все ко второй норме, для которой уже доказывали оценку из теоремы. Остается только выбрать $t = \frac{2}{\lambda_1 + \lambda_n}$, для которого как раз работает необходимая оценка.
    \end{enumerate}
\end{proof}
